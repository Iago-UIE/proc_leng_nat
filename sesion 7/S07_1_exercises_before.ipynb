{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with concepts\n",
    "\n",
    "This activity pretends that you play around with the concepts and python code, explore libraries, make experiments, and in general check theory with practice and with reality. To do that, you can use any tool you want including LLMs. Just try to have some findings after your experimentation process for most concepts we have seen. Use libraries like, NLTK, Spacy. Research how to implement the theory we have seen like ngrams, naive-bayes, language models...\n",
    "\n",
    "Yes, it is very similar than exercise S05_3, so if you have started it, you can start from the code you already have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams: [('This', 'is'), ('is', 'a'), ('a', 'simple'), ('simple', 'example'), ('example', 'to'), ('to', 'generate'), ('generate', 'n-grams')]\n",
      "Trigrams: [('This', 'is', 'a'), ('is', 'a', 'simple'), ('a', 'simple', 'example'), ('simple', 'example', 'to'), ('example', 'to', 'generate'), ('to', 'generate', 'n-grams')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text\n",
    "text = \"This is a simple example to generate n-grams\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Generate bigrams (2-grams)\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "print(\"Bigrams:\", bigrams)\n",
    "\n",
    "# Generate trigrams (3-grams)\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "print(\"Trigrams:\", trigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\iagoc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy: 94.20%\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load movie review data (positive and negative reviews)\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "# Create a feature extractor for text classification\n",
    "def extract_features(words):\n",
    "    return {word: True for word in words}\n",
    "\n",
    "# Prepare the dataset\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_set = [(extract_features(d), c) for (d, c) in documents[:1500]]\n",
    "test_set = [(extract_features(d), c) for (d, c) in documents[1500:]]\n",
    "\n",
    "# Train a Naive Bayes Classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate on the test set\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "print(f\"Classifier accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
